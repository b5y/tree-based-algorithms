{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I am going to present tree based algorithms (xgboost[link], lightgbm[link], catboost[link]) and hyperparameter tuning in LightGBM as an example library to show how it works. The idea of chosing LightGBM is that it is being well-known for winning solutions on kaggle[link].\n",
    "\n",
    "All three libraries are gradient boosting frameworks which uses decision trees. Some of them have parameter to precise the type of booster. For instance, LGBM has gbdt (gradient boosting decision tree), rf (random forest), dart (Dropouts meet Multiple Additive Regression Trees) and goss (Gradient-based One-Side Sampling).\n",
    "\n",
    "The main difference between LightGBM and other decision-tree frameworks is that it grows tree vertically while other algorithms grows trees horizontally. In the first picture you can see how **Light GBM** grows tree **leaf-wise** and second picture shows how algorithms grows **level-wise**. It will choose the leaf with max delta loss to grow. When growing the same leaf, Leaf-wise algorithm can reduce more loss than a level-wise algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/tree.png\" title=\"LightGBM's tree structure\" height=\"500\" width=\"500\" />\n",
    "<img src=\"img/other_tree.png\" title=\"Other frameworks tree structure\" height=\"500\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among other differences, xgboost doesn't support categorical features in comparison to LGBM or catboost. In other words, xgboost accepts only numerical values [https://stackoverflow.com/a/34346937].\n",
    "The only difficulties about using these libraries are parameter tuning. \n",
    "\n",
    "There are four approaches to tuning the hyperparameters of a machine learning model\n",
    "\n",
    "1. **Manual**: select hyperparameters based on intuition/experience/guessing, train the model with the hyperparameters, and score on the validation data. Repeat process until you run out of patience or are satisfied with the results.\n",
    "\n",
    "2. **Grid Search**: set up a grid of hyperparameter values and for each combination, train a model and score on the validation data. In this approach, every single combination of hyperparameters values is tried which can be very inefficient!\n",
    "\n",
    "3. **Random search**: set up a grid of hyperparameter values and select random combinations to train the model and score. The number of search iterations is set based on time/resources.\n",
    "\n",
    "4. **Automated Hyperparameter Tuning**: use methods such as gradient descent, Bayesian Optimization, or evolutionary algorithms to conduct a guided search for the best hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter optimization software\n",
    "- Hyperopt (Distributed Asynchronous Hyper-parameter Optimization)\n",
    "- Scikit-optimize (Sequential model-based optimization with a `scipy.optimize` interface )\n",
    "- Spearmint (Spearmint Bayesian optimization codebase from Harvard Intelligent Probabilistic Systems Group, outdated, but still popular)\n",
    "- GPyOpt (`Gaussian Process Optimization using GPy` from Sheffield Machine Learning Software, Department of Computer Science, The University of Sheffield) - very powerfull approach\n",
    "- RoBo (`RoBO: a Robust Bayesian Optimization framework` from AutoML-Freiburg, Germany) - very powerfull as well\n",
    "- SMAC3 (`Sequential Model-based Algorithm Configuration` aslo from AutoML-Freiburg, Germany)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 cases if you apply hyperparameter optimization:\n",
    "1. Underfitting (it can't even learn the train set)\n",
    "2. Good fitting (somewhere between underfitting and overfitting)\n",
    "3. Overfitting (model is so powerful that it just overfits the train set and can not generalize it at all)\n",
    "\n",
    "We should try to understand that if model is underfitting or overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide hyperparameters into two group.\n",
    "\n",
    "1. In red group we have the parmeters that constraint the model. If we have larger value of the parameter the heavier the constraint is \n",
    "    \n",
    "    (**overfitting -> underfitting**):\n",
    "   - Increasing it impedes fitting\n",
    "   - Increase it to reduce overfitting\n",
    "   - Decrease to allow model fit easier\n",
    "2. In the green group the highier the value, the more powerful the model\n",
    "    \n",
    "     (**underfitting -> overfitting**):\n",
    "   - Increasing it leads to a better fit (overfit) on train set\n",
    "   - Increase it, if model underfits\n",
    "   - Decrease if overfits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas lightgbm shap gc scikit-plot scikit-learn matplotlib hyperopt seaborn wordcloud missingno plotly yellowbrick eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPER PARAMS\n",
    "max_boosting_rounds = 4000\n",
    "\n",
    "import time\n",
    "notebookstart= time.time()\n",
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Viz\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import os\n",
    "from wordcloud import WordCloud\n",
    "import missingno as mn\n",
    "from yellowbrick.text import TSNEVisualizer\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='b5y', api_key='ZHRPWK21a22nkLu4XEkK')\n",
    "\n",
    "# Hide Warnings\n",
    "Warning = True\n",
    "if Warning is False:\n",
    "    import warnings\n",
    "    warnings.filterwarnings(action='ignore')\n",
    "    warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "    warnings.filterwarnings(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Modeling..\n",
    "import eli5\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import scikitplot as skplt\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Tf-Idf\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "np.random.seed(2018)\n",
    "\n",
    "from contextlib import contextmanager\n",
    "import re\n",
    "import string\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    \"\"\"\n",
    "    Taken from Konstantin Lopuhin https://www.kaggle.com/lopuhin\n",
    "    in script named : Mercari Golf: 0.3875 CV in 75 LOC, 1900 s\n",
    "    https://www.kaggle.com/lopuhin/mercari-golf-0-3875-cv-in-75-loc-1900-s\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(f'[{name}] done in {time.time() - t0:.0f} s')\n",
    "\n",
    "# Data Visualization\n",
    "def cloud(text, title, size = (10,7)):\n",
    "    # Processing Text\n",
    "    wordcloud = WordCloud(width=800, height=400,\n",
    "                          collocations=False\n",
    "                         ).generate(\" \".join(text))\n",
    "    \n",
    "    # Output Visualization\n",
    "    fig = plt.figure(figsize=size, dpi=80, facecolor='k',edgecolor='k')\n",
    "    plt.imshow(wordcloud,interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title, fontsize=25,color='w')\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = \"/l/musaevm1/data/quora_FILES\"\n",
    "embeddings = \"/embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DIR + \"/train.csv\"\n",
    "test = DIR + \"/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(train, index_col= 'qid')#.sample(50000)\n",
    "test = pd.read_csv(test, index_col= 'qid')#.sample(5000)\n",
    "testdex = test.index\n",
    "\n",
    "target_names = [\"Sincere\",\"Insincere\"]\n",
    "y = train['target'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Class Balance..\")\n",
    "train.target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,name in [(0,\"Sincere\"),(1,\"Insincere\")]:\n",
    "     cloud(train.loc[train.target == i,\"question_text\"], title=\"{} WordCloud\".format(name), size=[8,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################\n",
    "### Upvote this :) - https://www.kaggle.com/ogrellier/lgbm-with-words-and-chars-n-gram ####\n",
    "###########################################################################################\n",
    "\n",
    "# The better written the code, the easier the copy pasta\n",
    "\n",
    "# Contraction replacement patterns\n",
    "cont_patterns = [\n",
    "    (b'(W|w)on\\'t', b'will not'),\n",
    "    (b'(C|c)an\\'t', b'can not'),\n",
    "    (b'(I|i)\\'m', b'i am'),\n",
    "    (b'(A|a)in\\'t', b'is not'),\n",
    "    (b'(\\w+)\\'ll', b'\\g<1> will'),\n",
    "    (b'(\\w+)n\\'t', b'\\g<1> not'),\n",
    "    (b'(\\w+)\\'ve', b'\\g<1> have'),\n",
    "    (b'(\\w+)\\'s', b'\\g<1> is'),\n",
    "    (b'(\\w+)\\'re', b'\\g<1> are'),\n",
    "    (b'(\\w+)\\'d', b'\\g<1> would'),\n",
    "]\n",
    "patterns = [(re.compile(regex), repl) for (regex, repl) in cont_patterns]\n",
    "\n",
    "def prepare_for_char_n_gram(text):\n",
    "    \"\"\" Simple text clean up process\"\"\"\n",
    "    # 1. Go to lower case (only good for english)\n",
    "    # Go to bytes_strings as I had issues removing all \\n in r\"\"\n",
    "    clean = bytes(text.lower(), encoding=\"utf-8\")\n",
    "    # 2. Drop \\n and  \\t\n",
    "    clean = clean.replace(b\"\\n\", b\" \")\n",
    "    clean = clean.replace(b\"\\t\", b\" \")\n",
    "    clean = clean.replace(b\"\\b\", b\" \")\n",
    "    clean = clean.replace(b\"\\r\", b\" \")\n",
    "    # 3. Replace english contractions\n",
    "    for (pattern, repl) in patterns:\n",
    "        clean = re.sub(pattern, repl, clean)\n",
    "    # 4. Drop puntuation\n",
    "    # I could have used regex package with regex.sub(b\"\\p{P}\", \" \")\n",
    "    exclude = re.compile(b'[%s]' % re.escape(bytes(string.punctuation, encoding='utf-8')))\n",
    "    clean = b\" \".join([exclude.sub(b'', token) for token in clean.split()])\n",
    "    # 5. Drop numbers - as a scientist I don't think numbers are toxic ;-)\n",
    "    clean = re.sub(b\"\\d+\", b\" \", clean)\n",
    "    # 6. Remove extra spaces - At the end of previous operations we multiplied space accurences\n",
    "    clean = re.sub(b'\\s+', b' ', clean)\n",
    "    # Remove ending space if any\n",
    "    clean = re.sub(b'\\s+$', b'', clean)\n",
    "    # 7. Now replace words by words surrounded by # signs\n",
    "    # e.g. my name is bond would become #my# #name# #is# #bond#\n",
    "    # clean = re.sub(b\"([a-z]+)\", b\"#\\g<1>#\", clean)\n",
    "    clean = re.sub(b\" \", b\"# #\", clean)  # Replace space\n",
    "    clean = b\"#\" + clean + b\"#\"  # add leading and trailing #\n",
    "\n",
    "    return str(clean, 'utf-8')\n",
    "\n",
    "def count_regexp_occ(regexp=\"\", text=None):\n",
    "    \"\"\" Simple way to get the number of occurence of a regex\"\"\"\n",
    "    return len(re.findall(regexp, text))\n",
    "\n",
    "def get_indicators_and_clean_comments(df, text_var):\n",
    "    \"\"\"\n",
    "    Check all sorts of content as it may help find toxic comment\n",
    "    Though I'm not sure all of them improve scores\n",
    "    \"\"\"\n",
    "    # Count number of \\n\n",
    "    df[\"ant_slash_n\"] = df[text_var].apply(lambda x: count_regexp_occ(r\"\\n\", x))\n",
    "    # Get length in words and characters\n",
    "    df[\"raw_word_len\"] = df[text_var].apply(lambda x: len(x.split()))\n",
    "    df[\"raw_char_len\"] = df[text_var].apply(lambda x: len(x))\n",
    "    # Check number of upper case, if you're angry you may write in upper case\n",
    "    df[\"nb_upper\"] = df[text_var].apply(lambda x: count_regexp_occ(r\"[A-Z]\", x))\n",
    "    # Number of F words - f..k contains folk, fork,\n",
    "    df[\"nb_fk\"] = df[text_var].apply(lambda x: count_regexp_occ(r\"[Ff]\\S{2}[Kk]\", x))\n",
    "    # Number of S word\n",
    "    df[\"nb_sk\"] = df[text_var].apply(lambda x: count_regexp_occ(r\"[Ss]\\S{2}[Kk]\", x))\n",
    "    # Number of D words\n",
    "    df[\"nb_dk\"] = df[text_var].apply(lambda x: count_regexp_occ(r\"[dD]ick\", x))\n",
    "    # Number of occurence of You, insulting someone usually needs someone called : you\n",
    "    df[\"nb_you\"] = df[text_var].apply(lambda x: count_regexp_occ(r\"\\W[Yy]ou\\W\", x))\n",
    "    # Just to check you really refered to my mother ;-)\n",
    "    df[\"nb_mother\"] = df[text_var].apply(lambda x: count_regexp_occ(r\"\\Wmother\\W\", x))\n",
    "    # Just checking for toxic 19th century vocabulary\n",
    "    df[\"nb_ng\"] = df[text_var].apply(lambda x: count_regexp_occ(r\"\\Wnigger\\W\", x))\n",
    "    # Some Sentences start with a <:> so it may help\n",
    "    df[\"start_with_columns\"] = df[text_var].apply(lambda x: count_regexp_occ(r\"^\\:+\", x))\n",
    "    # Check for time stamp\n",
    "    df[\"has_timestamp\"] = df[text_var].apply(lambda x: count_regexp_occ(r\"\\d{2}|:\\d{2}\", x))\n",
    "    # Check for dates 18:44, 8 December 2010\n",
    "    df[\"has_date_long\"] = df[text_var].apply(lambda x: count_regexp_occ(r\"\\D\\d{2}:\\d{2}, \\d{1,2} \\w+ \\d{4}\", x))\n",
    "    # Check for date short 8 December 2010\n",
    "    df[\"has_date_short\"] = df[text_var].apply(lambda x: count_regexp_occ(r\"\\D\\d{1,2} \\w+ \\d{4}\", x))\n",
    "    # Check for http links\n",
    "    df[\"has_http\"] = df[text_var].apply(lambda x: count_regexp_occ(r\"http[s]{0,1}://\\S+\", x))\n",
    "    # check for mail\n",
    "    df[\"has_mail\"] = df[text_var].apply(\n",
    "        lambda x: count_regexp_occ(r'[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+', x)\n",
    "    )\n",
    "    # Looking for words surrounded by == word == or \"\"\"\" word \"\"\"\"\n",
    "    df[\"has_emphasize_equal\"] = df[text_var].apply(lambda x: count_regexp_occ(r\"\\={2}.+\\={2}\", x))\n",
    "    df[\"has_emphasize_quotes\"] = df[text_var].apply(lambda x: count_regexp_occ(r\"\\\"{4}\\S+\\\"{4}\", x))\n",
    "\n",
    "    # Now clean comments\n",
    "    df[\"clean_comment\"] = df[text_var].apply(lambda x: prepare_for_char_n_gram(x))\n",
    "\n",
    "    # Get the new length in words and characters\n",
    "    df[\"clean_word_len\"] = df[\"clean_comment\"].apply(lambda x: len(x.split()))\n",
    "    df[\"clean_char_len\"] = df[\"clean_comment\"].apply(lambda x: len(x))\n",
    "    # Number of different characters used in a comment\n",
    "    # Using the f word only will reduce the number of letters required in the comment\n",
    "    df[\"clean_chars\"] = df[\"clean_comment\"].apply(lambda x: len(set(x)))\n",
    "    df[\"clean_chars_ratio\"] = df[\"clean_comment\"].apply(lambda x: len(set(x))) / df[\"clean_comment\"].apply(\n",
    "        lambda x: 1 + min(99, len(x)))\n",
    "    \n",
    "def char_analyzer(text):\n",
    "    \"\"\"\n",
    "    This is used to split strings in small lots\n",
    "    I saw this in an article (I can't find the link anymore)\n",
    "    so <talk> and <talking> would have <Tal> <alk> in common\n",
    "    \"\"\"\n",
    "    tokens = text.split()\n",
    "    return [token[i: i + 3] for token in tokens for i in range(len(token) - 2)]\n",
    "\n",
    "all_text = pd.concat([train['question_text'],test['question_text']], axis =0)\n",
    "\n",
    "word_vect = TfidfVectorizer(\n",
    "            sublinear_tf=True,\n",
    "            strip_accents='unicode',\n",
    "            analyzer='word',\n",
    "            token_pattern=r'\\w{1,}',\n",
    "            stop_words='english',\n",
    "            ngram_range=(1, 2),\n",
    "            max_features=20000)\n",
    "\n",
    "char_vectorizer = TfidfVectorizer(\n",
    "            sublinear_tf=True,\n",
    "            strip_accents='unicode',\n",
    "            tokenizer=char_analyzer,\n",
    "            analyzer='word',\n",
    "            ngram_range=(1, 1),\n",
    "            max_features=50000)\n",
    "\n",
    "with timer(\"Word Grams TFIDF\"):\n",
    "    word_vect.fit(all_text)\n",
    "    train_word_features  = word_vect.transform(train['question_text'])\n",
    "    test_word_features  = word_vect.transform(test['question_text'])\n",
    "\n",
    "with timer(\"Character Grams TFIDF\"):\n",
    "    char_vectorizer.fit(all_text)\n",
    "    train_char_features = char_vectorizer.transform(train['question_text'])\n",
    "    test_char_features = char_vectorizer.transform(test['question_text'])\n",
    "\n",
    "with timer(\"Performing basic NLP\"):\n",
    "    get_indicators_and_clean_comments(train, 'question_text')\n",
    "    get_indicators_and_clean_comments(test,  'question_text')\n",
    "    \n",
    "    num_features = [f_ for f_ in train.columns\n",
    "                if f_ not in [\"question_text\", \"clean_comment\", \"remaining_chars\",\n",
    "                              'has_ip_address', 'target']]\n",
    "    \n",
    "# Get Sparse Matrix Feature Names..\n",
    "feature_names = word_vect.get_feature_names() + char_vectorizer.get_feature_names() + num_features\n",
    "del all_text; gc.collect()\n",
    "\n",
    "with timer(\"Sparse Combine\"):\n",
    "    X = hstack(\n",
    "        [\n",
    "            train_char_features,\n",
    "            train_word_features,\n",
    "            train[num_features]\n",
    "        ]\n",
    "    ).tocsr()\n",
    "\n",
    "    del train_char_features\n",
    "    gc.collect()\n",
    "\n",
    "    testing = hstack(\n",
    "        [\n",
    "            test_char_features,\n",
    "            test_word_features,\n",
    "            test[num_features]\n",
    "        ]\n",
    "    ).tocsr()\n",
    "    del test_char_features; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the visualizer and draw the vectors\n",
    "plt.figure(figsize = [15,9])\n",
    "tsne = TSNEVisualizer()\n",
    "n = 20000\n",
    "tsne.fit(X[:n], train.target[:n].map({1: target_names[1],0:target_names[0]}))\n",
    "tsne.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light Gradient Boosting Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=23, stratify=y)\n",
    "\n",
    "evals_result = {}  # to record eval results for plotting\n",
    "print(\"Light Gradient Boosting Classifier: \")\n",
    "\n",
    "modelstart= time.time()\n",
    "# LGBM Dataset Formatting \n",
    "lgtrain = lgb.Dataset(X_train, y_train,\n",
    "                feature_name=feature_names)\n",
    "lgvalid = lgb.Dataset(X_valid, y_valid,\n",
    "                feature_name=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try automated hyperparameter tuning with [**hyperopt**](https://github.com/hyperopt/hyperopt).\n",
    "\n",
    "_Hyperopt is an open-source Python library the implements Bayesian Optimization using the Tree Parzen Estimator algorithm to construct the surrogate function and select the next hyperparameter values to evaluate in the objective function. There are a number of other libraries such as Spearmint (Guassian process surrogate function) and SMAC (random forest regression surrogate function) sharing the same problem structure. The four parts of an optimization problem that we develop here will apply to all the libraries with only a change in syntax. Morevoer, the optimization methods as applied to the Gradient Boosting Machine will translate to other machine learning models or any problem where we have to minimize a function._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "from hyperopt import Trials\n",
    "from hyperopt import fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM parameters: https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "# Description: https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc\n",
    "# Define the search space\n",
    "space = {\n",
    "    'boosting_type': hp.choice('boosting_type', \n",
    "                                            [{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n",
    "                                             {'boosting_type': 'dart', 'subsample': hp.uniform('dart_subsample', 0.5, 1)},\n",
    "                                             ]),\n",
    "    'num_leaves': hp.quniform('num_leaves', 27, 32, 1),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.001), np.log(0.1)),\n",
    "    'feature_fraction': hp.loguniform('feature_fraction', np.log(0.7), np.log(0.9)),\n",
    "    'bagging_fraction': hp.loguniform('bagging_fraction', np.log(0.7), np.log(0.9)),\n",
    "    'min_split_gain': hp.loguniform('min_split_gain', np.log(0.05), np.log(.1)),\n",
    "    # 'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 10, 20, 5),\n",
    "    # 'max_depth': hp.quniform('max_depth', 8, 10, 5),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0),\n",
    "#     'is_unbalance': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- num_leaves: number of leaves in full tree, default: 31\n",
    "\n",
    "- learning_rate: _determines the impact of each tree on the final outcome. GBM works by starting with an initial estimate which is updated using the output of each tree. The learning parameter controls the magnitude of this change in the estimates. Typical values: 0.1, 0.001, 0.003…_\n",
    "\n",
    "- feature_fraction: _ Used when your boosting(discussed later) is random forest. 0.8 feature fraction means LightGBM will select 80% of parameters randomly in each iteration for building trees._\n",
    "\n",
    "- bagging_fraction: _specifies the fraction of data to be used for each iteration and is generally used to speed up the training and avoid overfitting._\n",
    "\n",
    "- min_child_samples: minimal number of data in one leaf. Can be used to deal with over-fitting\n",
    "\n",
    "- min_split_gain: the minimal gain to perform split (???)\n",
    "\n",
    "- reg_alpha: L1 regularization (https://en.wikipedia.org/wiki/Regularization_(mathematics))\n",
    "\n",
    "- reg_lambda: L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from the full space\n",
    "x = sample(space)\n",
    "\n",
    "# # Conditional logic to assign top-level keys\n",
    "subsample = x['boosting_type'].get('subsample', 1.0)\n",
    "x['boosting_type'] = x['boosting_type']['boosting_type']\n",
    "x['subsample'] = subsample\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import tpe\n",
    "\n",
    "# Create the algorithm\n",
    "tpe_algorithm = tpe.suggest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record results\n",
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from hyperopt import STATUS_OK\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "N_FOLDS = 5\n",
    "MAX_EVALS = 5\n",
    "\n",
    "def objective(hyperparameters):\n",
    "    \"\"\"Objective function for Gradient Boosting Machine Hyperparameter Optimization.\n",
    "       Writes a new line to `outfile` on every iteration\"\"\"\n",
    "    \n",
    "    # Keep track of evals\n",
    "    global ITERATION\n",
    "    \n",
    "    ITERATION += 1\n",
    "    \n",
    "    # Using early stopping to find number of trees trained\n",
    "    if 'n_estimators' in hyperparameters:\n",
    "        del hyperparameters['n_estimators']\n",
    "    \n",
    "    # Retrieve the subsample\n",
    "    subsample = hyperparameters['boosting_type'].get('subsample', 1.0)\n",
    "    \n",
    "    # Extract the boosting type and subsample to top level keys\n",
    "    hyperparameters['boosting_type'] = hyperparameters['boosting_type']['boosting_type']\n",
    "    hyperparameters['subsample'] = subsample\n",
    "    \n",
    "    # Make sure parameters that need to be integers are integers\n",
    "    for parameter_name in ['num_leaves', 'min_child_samples']:\n",
    "        hyperparameters[parameter_name] = int(hyperparameters[parameter_name])\n",
    "\n",
    "    start = timer()\n",
    "    \n",
    "    # Perform n_folds cross validation\n",
    "    cv_results = lgb.cv(hyperparameters, lgtrain, num_boost_round = 10000, nfold = N_FOLDS, \n",
    "                        early_stopping_rounds = 100, metrics = 'auc', seed = 50)\n",
    "\n",
    "    run_time = timer() - start\n",
    "    \n",
    "    # Extract the best score\n",
    "    best_score = cv_results['auc-mean'][-1]\n",
    "    \n",
    "    # Loss must be minimized\n",
    "    loss = 1 - best_score\n",
    "    \n",
    "    # Boosting rounds that returned the highest cv score\n",
    "    n_estimators = len(cv_results['auc-mean'])\n",
    "    \n",
    "    # Add the number of estimators to the hyperparameters\n",
    "    hyperparameters['n_estimators'] = n_estimators\n",
    "\n",
    "    # Write to the csv file ('a' means append)\n",
    "    of_connection = open(OUT_FILE, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([loss, hyperparameters, ITERATION, run_time, best_score])\n",
    "    of_connection.close()\n",
    "\n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'hyperparameters': hyperparameters, 'iteration': ITERATION,\n",
    "            'train_time': run_time, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "        \"objective\": \"binary\",\n",
    "        'metric': {'auc'},\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"num_threads\": 4,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"feature_fraction\": 0.8,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"num_leaves\": 31,\n",
    "        \"min_split_gain\": .1,\n",
    "        \"reg_alpha\": .1,\n",
    "        'verbose': -1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated Hyperparameter Optimization in Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variable\n",
    "global  ITERATION\n",
    "\n",
    "ITERATION = 0\n",
    "\n",
    "# Run optimization\n",
    "best = fmin(fn = objective, \n",
    "            space = space, \n",
    "            algo = tpe.suggest, \n",
    "            trials = trials,\n",
    "            max_evals = MAX_EVALS)\n",
    "\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go Go Go\n",
    "lgb_clf = lgb.train(\n",
    "    lgbm_params,\n",
    "    lgtrain,\n",
    "    num_boost_round= max_boosting_rounds,\n",
    "    valid_sets=[lgtrain, lgvalid],\n",
    "    valid_names=['train','valid'],\n",
    "    early_stopping_rounds=150,\n",
    "    evals_result=evals_result,\n",
    "    verbose_eval=100\n",
    ")\n",
    "\n",
    "del lgtrain, lgvalid\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = lgb.plot_metric(evals_result, metric='multi_logloss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pred = lgb_clf.predict(X_valid)\n",
    "_thresh = []\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    _thresh.append([thresh, metrics.f1_score(y_valid, (valid_pred>thresh).astype(int))])\n",
    "#     print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(y_valid, (valid_pred>thresh).astype(int))))\n",
    "\n",
    "_thresh = np.array(_thresh)\n",
    "best_id = _thresh[:,1].argmax()\n",
    "best_thresh = _thresh[best_id][0]\n",
    "print(\"Best Threshold: {}\\nF1 Score: {}\".format(best_thresh, _thresh[best_id][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed Diversification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allmodelstart= time.time()\n",
    "# Run Model with different Seeds\n",
    "multi_seed_pred = dict()\n",
    "all_feature_importance_df  = pd.DataFrame()\n",
    "\n",
    "optimal_rounds = lgb_clf.best_iteration\n",
    "\n",
    "lgtrain = lgb.Dataset(X, y, feature_name=feature_names)\n",
    "\n",
    "all_seeds = [27,22]\n",
    "for seeds_x in all_seeds:\n",
    "    modelstart= time.time()\n",
    "    print(\"Seed: \", seeds_x,)\n",
    "    # Go Go Go\n",
    "    lgbm_params[\"seed\"] = seeds_x\n",
    "    lgb_seed_clf = lgb.train(\n",
    "        lgbm_params,\n",
    "        lgtrain,\n",
    "        num_boost_round = optimal_rounds + 1,\n",
    "        verbose_eval=200)\n",
    "\n",
    "    # Feature Importance\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = feature_names\n",
    "    fold_importance_df[\"importance\"] = lgb_seed_clf.feature_importance()\n",
    "    all_feature_importance_df = pd.concat([all_feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    multi_seed_pred[seeds_x] =  list(lgb_seed_clf.predict(testing))\n",
    "    print(\"Model Runtime: %0.2f Minutes\"%((time.time() - modelstart)/60))\n",
    "    print(\"###########################################################################################\")\n",
    "    del lgb_seed_clf\n",
    "    \n",
    "del lgtrain, X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = all_feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "    by=\"importance\", ascending=False)[:50].index\n",
    "best_features = all_feature_importance_df.loc[all_feature_importance_df.feature.isin(cols)]\n",
    "plt.figure(figsize=(8,10))\n",
    "sns.barplot(x=\"importance\", y=\"feature\", \n",
    "            data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_importances.png')\n",
    "print(\"All Model Runtime: %0.2f Minutes\"%((time.time() - allmodelstart)/60))\n",
    "\n",
    "# To DataFrame\n",
    "sub_preds = pd.DataFrame.from_dict(multi_seed_pred).replace(0,0.000001)\n",
    "del multi_seed_pred; gc.collect();\n",
    "\n",
    "# Correlation Plot\n",
    "f, ax = plt.subplots(figsize=[8,6])\n",
    "sns.heatmap(sub_preds.corr(),\n",
    "            annot=True, fmt=\".2f\",cbar_kws={'label': 'Percentage %'},cmap=\"plasma\",ax=ax)\n",
    "ax.set_title(\"Correlation Plot for Seed Diversified Models\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take Mean over Seed prediction\n",
    "target_var = 'prediction'\n",
    "mean_sub = sub_preds.mean(axis=1).rename(target_var)\n",
    "mean_sub = (mean_sub > best_thresh).astype(int)\n",
    "mean_sub.index = testdex\n",
    "\n",
    "# Submit\n",
    "mean_sub.to_csv('submission.csv',index = True, header=True)\n",
    "print(mean_sub.value_counts(normalize=True))\n",
    "mean_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
